###
sum(cereal_pca_r$ind$contrib[1:10,1])
###
sum(cereal_pca_r$ind$contrib[1:20,1])
###
sum(cereal_pca_r$ind$contrib[1:74,1])
## Import data set from the web
url="http://lib.stat.cmu.edu/datasets/1993.expo/cereal"
cereals <- read.table(url, header=FALSE, as.is=TRUE, na.strings="-1")
# or from local file
cereals <- read.table("cereal.txt", header=TRUE, as.is=TRUE, na.strings="-1")
## Import data set from the web
url="http://lib.stat.cmu.edu/datasets/1993.expo/cereal"
cereals <- read.table(url, header=FALSE, as.is=TRUE, na.strings="-1")
# or from local file
cereals <- read.table("cereal.txt", header=TRUE, as.is=TRUE, na.strings="-1")
# or from local file
cereals <- read.table("/home/philipp/Programming/RProjects/basicDataManipulationAndGraphics/cereal.txt", header=TRUE, as.is=TRUE, na.strings="-1")
names(cereals) <- c('name','mfr','type','calories','protein','fat','sodium','fiber','carbo',
'sugars','shelf','potass','vitamins','weight','cups')
#checking for missing data and its number
sum(is.na(cereals))
#deleting missing values, creating new data frame cereal. There exist imputation methods, but we're not studying them.
cereals=na.omit(cereals)
str(cereals)
# Creating a factor
cereals$shelf <- factor(cereals$shelf, levels=1:3, ordered=TRUE)
cereals$shelf
table(cereals$shelf)
cereals$shelfC <- recode(cereals$shelf, " 1='low'; 2='medium'; 3='high' ")
# Basic statistical summary of the data set
summary(cereals)
## Skewness and kurtosis, need package "moments" to be loaded.
apply(cereals[,7:10],2, kurtosis)
## Skewness and kurtosis, need package "moments" to be loaded.
library(kurtosis)
## Skewness and kurtosis, need package "moments" to be loaded.
library("kurtosis")
library(tm)
library(ggplot2)
library(tm)
install.packages("tm")
library(tm)
library(ggplot2)
library(wordcount2)
install.packages("wordcloud")
library(wordcount2)
library(wordlcloud)
library(wordcloud)
source.pos = DirSource("/home/philipp/Programming/RProjects/NLP/txt_sentoken/pos", encoding="UTF-8")
corpus = Corpus(source.pos)
tdm = TermDocumentMatrix(corpus)
inspect(tdm[2000:2003,100:103])
freq = rowSums(as.matrix((tdm)))
install.packages()
install.packages(shiny)
"shiny"
install.packages("shiny")
library("shiny")
library(shiny)
runExample("01_hello")
library(shiny)
# Define UI for app that draws a histogram ----
ui <- fluidPage(
# App title ----
titlePanel("Hello Shiny!"),
# Sidebar layout with input and output definitions ----
sidebarLayout(
# Sidebar panel for inputs ----
sidebarPanel(
# Input: Slider for the number of bins ----
sliderInput(inputId = "bins",
label = "Number of bins:",
min = 1,
max = 50,
value = 30)
),
# Main panel for displaying outputs ----
mainPanel(
# Output: Histogram ----
plotOutput(outputId = "distPlot")
)
)
)
# Define server logic required to draw a histogram ----
server <- function(input, output) {
# Histogram of the Old Faithful Geyser Data ----
# with requested number of bins
# This expression that generates a histogram is wrapped in a call
# to renderPlot to indicate that:
#
# 1. It is "reactive" and therefore should be automatically
#    re-executed when inputs (input$bins) change
# 2. Its output type is a plot
output$distPlot <- renderPlot({
x    <- faithful$waiting
bins <- seq(min(x), max(x), length.out = input$bins + 1)
hist(x, breaks = bins, col = "#75AADB", border = "white",
xlab = "Waiting time to next eruption (in mins)",
main = "Histogram of waiting times")
})
}
shinyApp(ui = ui, server = server)
runApp("/home/philipp/Programming/dataVisualization/exercise1/App-1/app.R")
runApp("/home/philipp/Programming/dataVisualization/exercise1/App-1/app.R")
runApp("/home/philipp/Programming/dataVisualization/exercise1/App-1/app.R", display.mode = "showcase")
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
library(shiny)
h1("my title")
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
library(tm)
library(wordcloud)
library(SnowballC)
library(RWeka)
library(tm)
library(wordcloud)
library(SnowballC)
library(RWeka)
library(ggplot2)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
emails <- read.csv('emails.csv')
head(emails$text)
length(emails$text)
removeEmailAddress <- function(x) {
gsub(pattern = "\\w*[[:blank:]][[:punct:]][[:blank:]]\\w*[[:blank:]][[:punct:]][[:blank:]]com[[:blank:]]", replacement = "", x)
}
removeNumeration <- function(x) {
gsub(pattern = "[[:digit:]][[:blank:]]th", replacement = "", x)
}
pal = brewer.pal(8, "Blues")
pal = pal[-(1:3)]
set.seed(1234)
corpus <- VCorpus(VectorSource(emails$text))
inspect(corpus[[4]])
corpus_lowercase <- tm_map(corpus, content_transformer(tolower))
inspect(corpus_lowercase[[1]])
corpus_noEmailAddress <- tm_map(corpus_lowercase, content_transformer(removeEmailAddress))
inspect(corpus_noEmailAddress[[4]])
corpus_noNumeration <- tm_map(corpus_noEmailAddress, content_transformer(removeNumeration))
corpus.ngrams = tm_map(corpus_noNumeration,removeWords,c(stopwords(),"re", "ect", "hou", "e", "mail", "kaminski", "hou", "cc", "subject", "vince", "j", "enron"))
corpus.ngrams = tm_map(corpus.ngrams,removePunctuation)
corpus.ngrams = tm_map(corpus.ngrams,removeNumbers)
# tdm = TermDocumentMatrix(corpus_noEmailAddress, control=list(removePunctuation = T, removeNumbers = T, stopwords = c(stopwords(), "subject", "subject re", "vince", "hou", "ect", "kaminski"), stripWhitespace= T))
tdm = TermDocumentMatrix(corpus.ngrams, control=list(stripWhitespace= T))
tdm
tdm.small <- removeSparseTerms(tdm, sparse = 0.9)
tdm.small
freq = rowSums(as.matrix(tdm.small))
head(freq,10)
freq = sort(rowSums(as.matrix(tdm.small)), decreasing = T)
inspect(tdm)
word.cloud = wordcloud(words=names(freq), freq=freq, min.freq=500,
random.order=F, colors=pal)
BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
# tdm.bigram <- TermDocumentMatrix(corpus_noNumeration,
#                                 control = list (tokenize = BigramTokenizer, removeNumbers = T, stripWhitespace = T , removePunctuation = T, stopwords = c(stopwords(), " ect", "subject re", "ect ", "hou", "vince", "hou ", " hou", "cc subject", " am", "on ", "enron ", " enron", " pm", "j kaminski", "kaminski ", "http", "ect cc", " to")))
tdm.bigram <- TermDocumentMatrix(corpus.ngrams,
control = list (tokenize = BigramTokenizer, stripWhitespace = T))
tdm.bigram
tdm.bigram.small <- removeSparseTerms(tdm.bigram, 0.99)
inspect(tdm.bigram.small)
freqBigram = sort(rowSums(as.matrix(tdm.bigram.small)),decreasing = TRUE)
freqBigram.df = data.frame(word=names(freqBigram), freq=freqBigram)
head(freqBigram.df, 20)
wordcloud(freqBigram.df$word,freqBigram.df$freq,max.words=100,random.order = F, colors=pal)
ggplot(head(freqBigram.df,15), aes(reorder(word,freqBigram), freqBigram)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
ggplot(head(freqBigram.df,15), aes(reorder(word, freqBigram), freqBigram)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
ggplot(head(freqBigram.df,15), aes(reorder(word, freq), freqBigram)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
ggplot(head(freqBigram.df,15), aes(reorder(word, freqBigram), freq)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
ggplot(head(freqBigram.df,15), aes(reorder(word, freqBigram), freqBigram)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
ggplot(head(freqBigram.df,15), aes(reorder(word, freqBigram), freqBigram.df)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
ggplot(head(freqBigram.df,15), aes(reorder(word, freqBigram), freq)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
ggplot(head(freqBigram.df,15), aes(reorder(names(freqBigram), freqBigram), freqBigram)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
ggplot(head(freqBigram.df,15), aes(reorder(names(freqBigram), freqBigram), freqBigram)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
ggplot(head(freqBigram.df,15), aes(reorder(freqBigram, freqBigram), freqBigram)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
ggplot(head(freqBigram.df,15), aes(reorder(words(), freqBigram), freqBigram)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
ggplot(head(freqBigram.df,15), aes(reorder(words, freqBigram), freqBigram)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
ggplot(head(freqBigram.df,15), aes(reorder(word, freqBigram), freqBigram)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
ggplot(head(freqBigram.df,15), aes(reorder(freqBigram.df$word, freqBigram), freqBigram)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
ggplot(head(freqBigram.df,15), aes(reorder(word, freqBigram), freqBigram)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
TrigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3))
tdm.trigram = TermDocumentMatrix(corpus.ngrams,
control = list(tokenize = TrigramTokenizer, stripWhitespace = T))
freq = sort(rowSums(as.matrix(tdm.trigram)),decreasing = TRUE)
tdm.trigram
tdm.trigram.small <- removeSparseTerms(tdm.trigram, 0.99)
inspect(tdm.trigram.small)
freq = sort(rowSums(as.matrix(tdm.trigram.small)),decreasing = TRUE)
freq.df = data.frame(word=names(freq), freq=freq)
head(freq.df, 20)
wordcloud(freq.df$word,freq.df$freq,max.words=100,random.order = F, colors=pal)
tdm.trigram.small <- removeSparseTerms(tdm.trigram, 0.999)
inspect(tdm.trigram.small)
freq = sort(rowSums(as.matrix(tdm.trigram.small)),decreasing = TRUE)
freq.df = data.frame(word=names(freq), freq=freq)
head(freq.df, 20)
wordcloud(freq.df$word,freq.df$freq,max.words=100,random.order = F, colors=pal)
matrix.tdm = melt(as.matrix(tdm.small), value.name = "count")
library(reshape2)
matrix.tdm = melt(as.matrix(tdm.small), value.name = "count")
head(matrix.tdm)
ggplot(matrix.tdm, aes(x = Docs, y = Terms, fill = log10(count))) +
geom_tile(colour = "white") +
scale_fill_gradient(high="#FF0000" , low="#FFFFFF")+
ylab("Terms") +
theme(panel.background = element_blank()) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
ggplot(matrix.tdm, aes(x = Docs, y = Terms, fill = count)) +
geom_tile(colour = "white") +
scale_fill_gradient(high="#FF0000" , low="#FFFFFF")+
ylab("Terms") +
theme(panel.background = element_blank()) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
ggplot(matrix.tdm, aes(x = Docs, y = Terms, fill = log100(count))) +
geom_tile(colour = "white") +
scale_fill_gradient(high="#FF0000" , low="#FFFFFF")+
ylab("Terms") +
theme(panel.background = element_blank()) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
ggplot(matrix.tdm, aes(x = Docs, y = Terms, fill = log10(count))) +
geom_tile(colour = "white") +
scale_fill_gradient(high="#FF0000" , low="#FFFFFF")+
ylab("Terms") +
theme(panel.background = element_blank()) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
tdm.mini <- removeSparseTerms(tdm.small, sparse = 0.5)
matrix.tdm = melt(as.matrix(tdm.mini), value.name = "count")
head(matrix.tdm)
ggplot(matrix.tdm, aes(x = Docs, y = Terms, fill = log10(count))) +
geom_tile(colour = "white") +
scale_fill_gradient(high="#FF0000" , low="#FFFFFF")+
ylab("Terms") +
theme(panel.background = element_blank()) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
tdm.mini <- removeSparseTerms(tdm.small, sparse = 0.8)
matrix.tdm = melt(as.matrix(tdm.mini), value.name = "count")
head(matrix.tdm)
ggplot(matrix.tdm, aes(x = Docs, y = Terms, fill = log10(count))) +
geom_tile(colour = "white") +
scale_fill_gradient(high="#FF0000" , low="#FFFFFF")+
ylab("Terms") +
theme(panel.background = element_blank()) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
ggplot(matrix.tdm, aes(x = Docs, y = Terms, fill = log10(count))) +
geom_tile(colour = "black") +
scale_fill_gradient(high="#FF0000" , low="#FFFFFF")+
ylab("Terms") +
theme(panel.background = element_blank()) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
ggplot(matrix.tdm, aes(x = Docs, y = Terms, fill = log10(count))) +
geom_tile(colour = "grey") +
scale_fill_gradient(high="#FF0000" , low="#FFFFFF")+
ylab("Terms") +
theme(panel.background = element_blank()) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
ggplot(matrix.tdm, aes(x = Docs, y = Terms, fill = log10(count))) +
geom_tile(colour = "grey") +
scale_fill_gradient(high="#2600ff" , low="#00fff7")+
ylab("Terms") +
theme(panel.background = element_blank()) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
ggplot(matrix.tdm, aes(x = Docs, y = Terms, fill = log10(count))) +
geom_tile(colour = "white") +
scale_fill_gradient(high="#2600ff" , low="#00fff7")+
ylab("Terms") +
theme(panel.background = element_blank()) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
ggplot(matrix.tdm, aes(x = Docs, y = Terms, fill = log10(count))) +
geom_tile(colour = "white") +
scale_fill_gradient(high="#2600ff" , low="#00fff7")+
ylab("Terms") +
xlab("Emails") +
theme(panel.background = element_blank()) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
ggplot(matrix.tdm, aes(x = Docs, y = Terms, fill = log10(count))) +
geom_tile(colour = "black") +
scale_fill_gradient(high="#ffffff" , low="#000000")+
ylab("Terms") +
xlab("E-Mails") +
theme(panel.background = element_blank()) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
tdm.mini <- removeSparseTerms(tdm.small, sparse = 0.4)
matrix.tdm = melt(as.matrix(tdm.mini), value.name = "count")
head(matrix.tdm)
ggplot(matrix.tdm, aes(x = Docs, y = Terms, fill = log10(count))) +
geom_tile(colour = "black") +
scale_fill_gradient(high="#ffffff" , low="#000000")+
ylab("Terms") +
xlab("E-Mails") +
theme(panel.background = element_blank()) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
tdm.mini <- removeSparseTerms(tdm.small, sparse = 0.6)
matrix.tdm = melt(as.matrix(tdm.mini), value.name = "count")
head(matrix.tdm)
ggplot(matrix.tdm, aes(x = Docs, y = Terms, fill = log10(count))) +
geom_tile(colour = "black") +
scale_fill_gradient(high="#ffffff" , low="#000000")+
ylab("Terms") +
xlab("E-Mails") +
theme(panel.background = element_blank()) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
tdm.mini <- removeSparseTerms(tdm.small, sparse = 0.8)
matrix.tdm = melt(as.matrix(tdm.mini), value.name = "count")
head(matrix.tdm)
ggplot(matrix.tdm, aes(x = Docs, y = Terms, fill = log10(count))) +
geom_tile(colour = "black") +
scale_fill_gradient(high="#ffffff" , low="#000000")+
ylab("Terms") +
xlab("E-Mails") +
theme(panel.background = element_blank()) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
word.cloud = wordcloud(words=names(freq), freq=freq, min.freq=500,
random.order=F, colors=pal)
library(tm)
library(wordcloud)
library(SnowballC)
library(RWeka)
library(ggplot2)
library(reshape2)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
emails <- read.csv('emails.csv')
head(emails$text)
length(emails$text)
removeEmailAddress <- function(x) {
gsub(pattern = "\\w*[[:blank:]][[:punct:]][[:blank:]]\\w*[[:blank:]][[:punct:]][[:blank:]]com[[:blank:]]", replacement = "", x)
}
removeNumeration <- function(x) {
gsub(pattern = "[[:digit:]][[:blank:]]th", replacement = "", x)
}
pal = brewer.pal(8, "Blues")
pal = pal[-(1:3)]
set.seed(1234)
corpus <- VCorpus(VectorSource(emails$text))
inspect(corpus[[4]])
corpus_lowercase <- tm_map(corpus, content_transformer(tolower))
inspect(corpus_lowercase[[1]])
corpus_noEmailAddress <- tm_map(corpus_lowercase, content_transformer(removeEmailAddress))
inspect(corpus_noEmailAddress[[4]])
corpus_noNumeration <- tm_map(corpus_noEmailAddress, content_transformer(removeNumeration))
corpus.ngrams = tm_map(corpus_noNumeration,removeWords,c(stopwords(),"re", "ect", "hou", "e", "mail", "kaminski", "hou", "cc", "subject", "vince", "j", "enron"))
corpus.ngrams = tm_map(corpus.ngrams,removePunctuation)
corpus.ngrams = tm_map(corpus.ngrams,removeNumbers)
tdm = TermDocumentMatrix(corpus.ngrams, control=list(stripWhitespace= T))
tdm
tdm.small <- removeSparseTerms(tdm, sparse = 0.9)
tdm.small
freq = rowSums(as.matrix(tdm.small))
head(freq,10)
freq = sort(rowSums(as.matrix(tdm.small)), decreasing = T)
inspect(tdm)
word.cloud = wordcloud(words=names(freq), freq=freq, min.freq=500,
random.order=F, colors=pal)
tdm.mini <- removeSparseTerms(tdm.small, sparse = 0.8)
matrix.tdm = melt(as.matrix(tdm.mini), value.name = "count")
head(matrix.tdm)
ggplot(matrix.tdm, aes(x = Docs, y = Terms, fill = log10(count))) +
geom_tile(colour = "black") +
scale_fill_gradient(high="#ffffff" , low="#000000")+
ylab("Terms") +
xlab("E-Mails") +
theme(panel.background = element_blank()) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
tdm.bigram <- TermDocumentMatrix(corpus.ngrams,
control = list (tokenize = BigramTokenizer, stripWhitespace = T))
tdm.bigram
tdm.bigram.small <- removeSparseTerms(tdm.bigram, 0.99)
inspect(tdm.bigram.small)
freqBigram = sort(rowSums(as.matrix(tdm.bigram.small)),decreasing = TRUE)
freqBigram.df = data.frame(word=names(freqBigram), freq=freqBigram)
head(freqBigram.df, 20)
wordcloud(freqBigram.df$word,freqBigram.df$freq,max.words=100,random.order = F, colors=pal)
ggplot(head(freqBigram.df,15),
aes(reorder(word, freqBigram),
freqBigram)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Bigrams") + ylab("Frequency") +
ggtitle("Most frequent bigrams")
TrigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3))
tdm.trigram = TermDocumentMatrix(corpus.ngrams,
control = list(tokenize = TrigramTokenizer, stripWhitespace = T))
tdm.trigram
tdm.trigram.small <- removeSparseTerms(tdm.trigram, 0.999)
inspect(tdm.trigram.small)
freq = sort(rowSums(as.matrix(tdm.trigram.small)),decreasing = TRUE)
freq.df = data.frame(word=names(freq), freq=freq)
head(freq.df, 20)
wordcloud(freq.df$word,freq.df$freq,max.words=100,random.order = F, colors=pal)
ggplot(head(freq.df,15), aes(reorder(word,freq), freq)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Trigrams") + ylab("Frequency") +
ggtitle("Most frequent trigrams")
freq = sort(rowSums(as.matrix(tdm.bigram.small)),decreasing = TRUE)
freq.df = data.frame(word=names(freq), freq=freq)
head(freq.df, 20)
wordcloud(freq.df$word,freq.df$freq,max.words=100,random.order = F, colors=pal)
ggplot(head(freq.df,15), aes(reorder(word,freq), freq)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Trigrams") + ylab("Frequency") +
ggtitle("Most frequent trigrams")
ggplot(head(freq.df,15), aes(reorder(word,freq), freq)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Bigram") + ylab("Frequency") +
ggtitle("Most Frequent Bigrams")
removeURLs <- function(x){
gsub(pattern= "http[[:blank:]]www\\w*com")
}
corpus.ngrams = tm_map(corpus.ngrams, removeURs)
corpus.ngrams = tm_map(corpus.ngrams, removeURLs)
removeURLs <- function(x){
gsub(pattern= "http[[:blank:]]www\\w*com", replacement = "", x)
}
corpus.ngrams = tm_map(corpus.ngrams, removeURLs)
corpus.ngrams = tm_map(corpus.ngrams,removeNumbers)
BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
tdm.bigram <- TermDocumentMatrix(corpus.ngrams,
control = list (tokenize = BigramTokenizer, stripWhitespace = T))
TrigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3))
tdm.trigram = TermDocumentMatrix(corpus.ngrams,
control = list(tokenize = TrigramTokenizer, stripWhitespace = T))
tdm.trigram
tdm.trigram.small <- removeSparseTerms(tdm.trigram, 0.999)
inspect(tdm.trigram.small)
freq = sort(rowSums(as.matrix(tdm.trigram.small)),decreasing = TRUE)
freq.df = data.frame(word=names(freq), freq=freq)
head(freq.df, 20)
wordcloud(freq.df$word,freq.df$freq,max.words=100,random.order = F, colors=pal)
ggplot(head(freq.df,15), aes(reorder(word,freq), freq)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Trigram") + ylab("Frequency") +
ggtitle("Most Frequent Trigrams")
corpus.ngrams = tm_map(corpus_noNumeration,removeWords,c(stopwords(),"re", "ect", "hou", "e", "mail", "kaminski", "hou", "cc", "subject", "vince", "j", "enron", "http"))
corpus.ngrams = tm_map(corpus.ngrams,removePunctuation)
corpus.ngrams = tm_map(corpus.ngrams, removeURLs)
corpus.ngrams = tm_map(corpus.ngrams,removeNumbers)
TrigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3))
tdm.trigram = TermDocumentMatrix(corpus.ngrams,
control = list(tokenize = TrigramTokenizer, stripWhitespace = T))
tdm.trigram
tdm.trigram.small <- removeSparseTerms(tdm.trigram, 0.999)
inspect(tdm.trigram.small)
freq = sort(rowSums(as.matrix(tdm.trigram.small)),decreasing = TRUE)
freq.df = data.frame(word=names(freq), freq=freq)
head(freq.df, 20)
wordcloud(freq.df$word,freq.df$freq,max.words=100,random.order = F, colors=pal)
ggplot(head(freq.df,15), aes(reorder(word,freq), freq)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Trigram") + ylab("Frequency") +
ggtitle("Most Frequent Trigrams")
wordcloud(freq.df$word,freq.df$freq,max.words=100,random.order = F, colors=pal)
