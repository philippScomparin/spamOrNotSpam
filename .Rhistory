cereal_pca_r
#summary of the numerical output
summary(cereal_pca_r)
#Working on the map of points, representation of individuals
plot(cereal_pca_r, cex=0.7)
# coloring points by variable shelf
plot(cereal_pca_r, cex=0.8, shadow=TRUE, habillage=9)
# change individual color by group
fviz_pca_ind(cereal_pca_r,  habillage="shelf")
fviz_pca_ind(cereal_pca_r,  label="none", habillage="shelf")
#labels for those points with cosin squared greater than 0.7, for example.
# It selects observations with cos2[,1]+cos2[,2]>0.7
plot(cereal_pca_r, cex=0.7, shadow=TRUE, habillage=9, invisible="quali", select="cos2 0.7")
# plotting only previously selected observations
plot(cereal_pca_r, cex=0.7, shadow=TRUE, habillage=9, invisible="quali", select="cos2 0.7", unselect=1)
#selecting a color for unselected points
plot(cereal_pca_r, cex=0.7, shadow=TRUE, habillage=9, invisible="quali", select="cos2 0.7", unselect="grey70")
# To select the five observations that contribute the most to the two first components, the more extreme individuals in both components
plot(cereal_pca_r, cex=0.7, shadow=TRUE, habillage=9, invisible="quali", select="cos2 5", unselect=1)
#selecting particular individuals by their names
plot(cereal_pca_r, cex=0.8, shadow=TRUE, habillage=9, invisible="quali", select=c("Trix", "H_N_", "Whts"))
#selecting particular individuals by their row in the dataset
plot(cereal_pca_r, cex=0.8, shadow=TRUE, habillage=9, invisible="quali", select=1:10)
# Controlling automatically the color of individuals using the cos2 values (the quality of the individuals on the factor map)
fviz_pca_ind(cereal_pca_r, col.ind="cos2", repel=TRUE) +
scale_color_gradient2(low="white", mid="blue",
high="red", midpoint=0.50)
fviz_pca_ind(cereal_pca_r, pointsize = "cos2",
pointshape = 21, fill = "#E7B800",
repel = TRUE # Avoid text overlapping (slow if many points)
)
# What if I want the previous plot but showing also the shelf each cereal is on?
# Solution
newdf=data.frame(cos2=cereal_pca_r$ind$cos2[,1]+cereal_pca_r$ind$cos2[,2],shelf=cereal.pc$shelf,
PC1=cereal_pca_r$ind$coord[,1],PC2=cereal_pca_r$ind$coord[,2])
ggplot(data=newdf, aes(x=PC1, y=PC2, colour=cos2, shape=shelf))+
geom_text(aes(label=rownames(newdf)), hjust=1.5)+geom_jitter(size=2)
## Working on variables, circle of correlations
plot(cereal_pca_r, choix="var")
## or with package factoextra
fviz_pca_var(cereal_pca_r)
# Ploting the 3 variables that contribute the most to the representation
plot(cereal_pca_r, shadow=TRUE,choix="var", select="contrib 3" )
# selecting variables by their contributions, quality of representation greater than 0.7
plot(cereal_pca_r, shadow=TRUE,choix="var", select="cos2 0.7" )
# control variable colors using their contribution
fviz_pca_var(cereal_pca_r, col.var="contrib")
# Change the gradient color
fviz_pca_var(cereal_pca_r, col.var="contrib")+
scale_color_gradient2(low="white", mid="blue",
high="red", midpoint=55)+theme_bw()
# Quality of each variable representation on these two dimensions
cereal_pca_r$var$cos2[,1:2][,1]+ cereal_pca_r$var$cos2[,1:2][,2]
# First a table, then a barplot of variables contribution to each dimension with ggplot
rbind(cereal_pca_r$var$contrib, TOTAL=colSums(cereal_pca_r$var$contrib))
var.contrib=cereal_pca_r$var$contrib
my.grid=expand.grid(x=rownames(var.contrib), y=colnames(var.contrib))
my.grid$values= as.vector(var.contrib)
ggplot(my.grid, aes(x=y, y=values))+geom_bar(stat="identity", aes(fill=x), position=position_dodge())+
scale_fill_brewer(palette="Dark2")
ggplot(my.grid, aes(x=x, y=values))+geom_bar(stat="identity", aes(fill=y), position=position_dodge())
### Objects (observations) contribution
objcontrib=data.frame(C1=cereal_pca_r$ind$contrib[,1],C2=cereal_pca_r$ind$contrib[,2],n=rownames(cereal.pc))
# Barplots of object contributions to PC 1 with ggplot and package gridExtra
G1=ggplot(objcontrib[1:36,],aes(x=n, y=C1))+geom_bar(position=position_dodge(), stat="identity", fill="steelblue")+geom_text(aes(label=n), vjust=1.6, color="white", size=2.5, position=position_dodge(0.9))+geom_hline(yintercept=100/74)
G2=ggplot(objcontrib[31:74,],aes(x=n, y=C1))+geom_bar(position=position_dodge(), stat="identity", fill="steelblue")+geom_text(aes(label=n), vjust=1.6, color="white", size=2.5, position=position_dodge(0.9))+geom_hline(yintercept=100/74)
grid.arrange(G1,G2,nrow=2)
#If you want to order observations by the first component value (score), make a data frame with the two first scores, for instance
obsor=data.frame(C1=cereal_pca_r$ind$coord[,1],C2=cereal_pca_r$ind$coord[,2])
head(obsor[order(obsor[,1], decreasing=TRUE),])
# Checking some equalities
sum(cereal_pca_r$var$cos2[1,1:8])
sum(cereal_pca_r$ind$cos2[1,])
###
sum(cereal_pca_r$var$cor[1:8,1]^2)
mean(cereal_pca_r$ind$coord[,1]^2)
###
sum(cereal_pca_r$ind$contrib[,1])
sum(cereal_pca_r$var$contrib[1,])
#scree plot
par(mfrow=c(1,1))
plot(cereal_pca_r$eig[,1], type="l")
points(cereal_pca_r$eig[,1])
# scree plot (barplot type)
barplot(cereal_pca_r$eig[,1], names.arg=rownames(cereal_pca_r$eig))
#biplot
fviz_pca_biplot(cereal_pca_r, repel=TRUE)
# Eigenvectors. They are collinear with the correlations between variables and
# components.
cereal_pca_r$svd$V
cereal_pca_r$svd$V[,1] # first eigenvector, coefficients for the linear combination
# that defines the first principal component.
# correlations are the corresponding entry in the corresponding eigenvector times the corresponding
# singular value
cereal_pca_r$var$cor[1,1] # correlation first var first component
cereal_pca_r$svd$V[1,1]*cereal_pca_r$svd$vs[1]
cereal_pca_r$var$cor[2,1] # correlation second variable first component
cereal_pca_r$svd$V[2,1]*cereal_pca_r$svd$vs[1]
# correlations between variables and dimensions and significance tests
# For the first (second) component, are there any differences in the categorical variable?
#
dimdesc(cereal_pca_r,axes=c(1,2))
concat1 = cbind.data.frame(shelf=cereal.pc[,9],cereal_pca_r$ind$coord[,1:2])
boxplot(concat1[,2]~concat1[,1])
summary(aov(concat1[,2]~concat1[,1]))
summary(lm(concat1[,2]~concat1[,1]))
# Determining the number of components with cross validation
estim_ncpPCA(cereal.pc, ncp.min = 0, ncp.max = 5,
scale = TRUE, method.cv = c("Kfold"), nbsim = 100,
pNA = 0.05, ind.sup=NULL, quanti.sup=NULL, quali.sup=9,
threshold=1e-4, verbose = TRUE)
library(tidyverse) #data manipilation
library(GGally) # nice scatterplot matrix
library(FactoMineR) # PCA computation
library(factoextra) # nice plotting for PCA objects
library(missMDA) # to determine number of PC's through crossvalidation
library(gridExtra) # to build grid of plots
#check you have the correct data set
cereals <- read.table("/home/philipp/Programming/RProjects/PCAandBiplots/cerealdata.txt", header=TRUE, as.is=TRUE, na.strings="-1")
cereals1=na.omit(cereals)
rownames(cereals1)=abbreviate(cereals1$Name)
cereal.pc=dplyr::select(cereals1,calories,protein,fat,sodium,fiber,carbo,sugars,potass,shelf)
cereal.pc=na.omit(cereal.pc)
head(cereal.pc)
cereal.pc$shelf=as.factor(cereal.pc$shelf)
#summary of the variables, shelf is a factor
summary(cereal.pc)
str(cereal.pc)
#covariance matrix, very different variances
cov(cereal.pc[,-9])
# Before starting with PCA, a nice scatterplot matrix
ggpairs(cereal.pc, lower = list(continuous="points",combo="facetdensity",mapping=aes(color=shelf)))
cereal_pca_r=PCA(cereal.pc,quali.sup=9,ncp=8,scale.unit=TRUE, graph=FALSE)
# by default dimensions 1 and 2 are plotted. We are using that option. To change them use axes=c(1,3).
# type cereal_pca_r to see the extensive list of results provided in the output of PCA()
cereal_pca_r
#summary of the numerical output
summary(cereal_pca_r)
#Working on the map of points, representation of individuals
plot(cereal_pca_r, cex=0.7)
# coloring points by variable shelf
plot(cereal_pca_r, cex=0.8, shadow=TRUE, habillage=9)
# change individual color by group
fviz_pca_ind(cereal_pca_r,  habillage="shelf")
fviz_pca_ind(cereal_pca_r,  label="none", habillage="shelf")
#labels for those points with cosin squared greater than 0.7, for example.
# It selects observations with cos2[,1]+cos2[,2]>0.7
plot(cereal_pca_r, cex=0.7, shadow=TRUE, habillage=9, invisible="quali", select="cos2 0.7")
# plotting only previously selected observations
plot(cereal_pca_r, cex=0.7, shadow=TRUE, habillage=9, invisible="quali", select="cos2 0.7", unselect=1)
#selecting a color for unselected points
plot(cereal_pca_r, cex=0.7, shadow=TRUE, habillage=9, invisible="quali", select="cos2 0.7", unselect="grey70")
# To select the five observations that contribute the most to the two first components, the more extreme individuals in both components
plot(cereal_pca_r, cex=0.7, shadow=TRUE, habillage=9, invisible="quali", select="cos2 5", unselect=1)
#selecting particular individuals by their names
plot(cereal_pca_r, cex=0.8, shadow=TRUE, habillage=9, invisible="quali", select=c("Trix", "H_N_", "Whts"))
#selecting particular individuals by their row in the dataset
plot(cereal_pca_r, cex=0.8, shadow=TRUE, habillage=9, invisible="quali", select=1:10)
# Controlling automatically the color of individuals using the cos2 values (the quality of the individuals on the factor map)
fviz_pca_ind(cereal_pca_r, col.ind="cos2", repel=TRUE) +
scale_color_gradient2(low="white", mid="blue",
high="red", midpoint=0.50)
fviz_pca_ind(cereal_pca_r, pointsize = "cos2",
pointshape = 21, fill = "#E7B800",
repel = TRUE # Avoid text overlapping (slow if many points)
)
# What if I want the previous plot but showing also the shelf each cereal is on?
# Solution
newdf=data.frame(cos2=cereal_pca_r$ind$cos2[,1]+cereal_pca_r$ind$cos2[,2],shelf=cereal.pc$shelf,
PC1=cereal_pca_r$ind$coord[,1],PC2=cereal_pca_r$ind$coord[,2])
ggplot(data=newdf, aes(x=PC1, y=PC2, colour=cos2, shape=shelf))+
geom_text(aes(label=rownames(newdf)), hjust=1.5)+geom_jitter(size=2)
## Working on variables, circle of correlations
plot(cereal_pca_r, choix="var")
## or with package factoextra
fviz_pca_var(cereal_pca_r)
# Ploting the 3 variables that contribute the most to the representation
plot(cereal_pca_r, shadow=TRUE,choix="var", select="contrib 3" )
# selecting variables by their contributions, quality of representation greater than 0.7
plot(cereal_pca_r, shadow=TRUE,choix="var", select="cos2 0.7" )
# control variable colors using their contribution
fviz_pca_var(cereal_pca_r, col.var="contrib")
library(tidyverse) #data manipilation
library(GGally) # nice scatterplot matrix
library(FactoMineR) # PCA computation
library(factoextra) # nice plotting for PCA objects
library(missMDA) # to determine number of PC's through crossvalidation
library(gridExtra) # to build grid of plots
#check you have the correct data set
cereals <- read.table("/home/philipp/Programming/RProjects/PCAandBiplots/cerealdata.txt", header=TRUE, as.is=TRUE, na.strings="-1")
cereals1=na.omit(cereals)
rownames(cereals1)=abbreviate(cereals1$Name)
cereal.pc=dplyr::select(cereals1,calories,protein,fat,sodium,fiber,carbo,sugars,potass,shelf)
cereal.pc=na.omit(cereal.pc)
head(cereal.pc)
cereal.pc$shelf=as.factor(cereal.pc$shelf)
#summary of the variables, shelf is a factor
summary(cereal.pc)
str(cereal.pc)
#covariance matrix, very different variances
cov(cereal.pc[,-9])
# Before starting with PCA, a nice scatterplot matrix
ggpairs(cereal.pc, lower = list(continuous="points",combo="facetdensity",mapping=aes(color=shelf)))
cereal_pca_r=PCA(cereal.pc,quali.sup=9,ncp=8,scale.unit=TRUE, graph=FALSE)
# by default dimensions 1 and 2 are plotted. We are using that option. To change them use axes=c(1,3).
# type cereal_pca_r to see the extensive list of results provided in the output of PCA()
cereal_pca_r
#summary of the numerical output
summary(cereal_pca_r)
#Working on the map of points, representation of individuals
plot(cereal_pca_r, cex=0.7)
# coloring points by variable shelf
plot(cereal_pca_r, cex=0.8, shadow=TRUE, habillage=9)
# change individual color by group
fviz_pca_ind(cereal_pca_r,  habillage="shelf")
fviz_pca_ind(cereal_pca_r,  label="none", habillage="shelf")
#labels for those points with cosin squared greater than 0.7, for example.
# It selects observations with cos2[,1]+cos2[,2]>0.7
plot(cereal_pca_r, cex=0.7, shadow=TRUE, habillage=9, invisible="quali", select="cos2 0.7")
# plotting only previously selected observations
plot(cereal_pca_r, cex=0.7, shadow=TRUE, habillage=9, invisible="quali", select="cos2 0.7", unselect=1)
#selecting a color for unselected points
plot(cereal_pca_r, cex=0.7, shadow=TRUE, habillage=9, invisible="quali", select="cos2 0.7", unselect="grey70")
# To select the five observations that contribute the most to the two first components, the more extreme individuals in both components
plot(cereal_pca_r, cex=0.7, shadow=TRUE, habillage=9, invisible="quali", select="cos2 5", unselect=1)
#selecting particular individuals by their names
plot(cereal_pca_r, cex=0.8, shadow=TRUE, habillage=9, invisible="quali", select=c("Trix", "H_N_", "Whts"))
#selecting particular individuals by their row in the dataset
plot(cereal_pca_r, cex=0.8, shadow=TRUE, habillage=9, invisible="quali", select=1:10)
# Controlling automatically the color of individuals using the cos2 values (the quality of the individuals on the factor map)
fviz_pca_ind(cereal_pca_r, col.ind="cos2", repel=TRUE) +
scale_color_gradient2(low="white", mid="blue",
high="red", midpoint=0.50)
fviz_pca_ind(cereal_pca_r, pointsize = "cos2",
pointshape = 21, fill = "#E7B800",
repel = TRUE # Avoid text overlapping (slow if many points)
)
# What if I want the previous plot but showing also the shelf each cereal is on?
# Solution
newdf=data.frame(cos2=cereal_pca_r$ind$cos2[,1]+cereal_pca_r$ind$cos2[,2],shelf=cereal.pc$shelf,
PC1=cereal_pca_r$ind$coord[,1],PC2=cereal_pca_r$ind$coord[,2])
ggplot(data=newdf, aes(x=PC1, y=PC2, colour=cos2, shape=shelf))+
geom_text(aes(label=rownames(newdf)), hjust=1.5)+geom_jitter(size=2)
## Working on variables, circle of correlations
plot(cereal_pca_r, choix="var")
## or with package factoextra
fviz_pca_var(cereal_pca_r)
# Ploting the 3 variables that contribute the most to the representation
plot(cereal_pca_r, shadow=TRUE,choix="var", select="contrib 3" )
# selecting variables by their contributions, quality of representation greater than 0.7
plot(cereal_pca_r, shadow=TRUE,choix="var", select="cos2 0.7" )
# control variable colors using their contribution
fviz_pca_var(cereal_pca_r, col.var="contrib")
# Change the gradient color
fviz_pca_var(cereal_pca_r, col.var="contrib")+
scale_color_gradient2(low="white", mid="blue",
high="red", midpoint=55)+theme_bw()
# Quality of each variable representation on these two dimensions
cereal_pca_r$var$cos2[,1:2][,1]+ cereal_pca_r$var$cos2[,1:2][,2]
# First a table, then a barplot of variables contribution to each dimension with ggplot
rbind(cereal_pca_r$var$contrib, TOTAL=colSums(cereal_pca_r$var$contrib))
var.contrib=cereal_pca_r$var$contrib
my.grid=expand.grid(x=rownames(var.contrib), y=colnames(var.contrib))
my.grid$values= as.vector(var.contrib)
ggplot(my.grid, aes(x=y, y=values))+geom_bar(stat="identity", aes(fill=x), position=position_dodge())+
scale_fill_brewer(palette="Dark2")
ggplot(my.grid, aes(x=x, y=values))+geom_bar(stat="identity", aes(fill=y), position=position_dodge())
### Objects (observations) contribution
objcontrib=data.frame(C1=cereal_pca_r$ind$contrib[,1],C2=cereal_pca_r$ind$contrib[,2],n=rownames(cereal.pc))
# Barplots of object contributions to PC 1 with ggplot and package gridExtra
G1=ggplot(objcontrib[1:36,],aes(x=n, y=C1))+geom_bar(position=position_dodge(), stat="identity", fill="steelblue")+geom_text(aes(label=n), vjust=1.6, color="white", size=2.5, position=position_dodge(0.9))+geom_hline(yintercept=100/74)
G2=ggplot(objcontrib[31:74,],aes(x=n, y=C1))+geom_bar(position=position_dodge(), stat="identity", fill="steelblue")+geom_text(aes(label=n), vjust=1.6, color="white", size=2.5, position=position_dodge(0.9))+geom_hline(yintercept=100/74)
grid.arrange(G1,G2,nrow=2)
#If you want to order observations by the first component value (score), make a data frame with the two first scores, for instance
obsor=data.frame(C1=cereal_pca_r$ind$coord[,1],C2=cereal_pca_r$ind$coord[,2])
head(obsor[order(obsor[,1], decreasing=TRUE),])
# Checking some equalities
sum(cereal_pca_r$var$cos2[1,1:8])
sum(cereal_pca_r$ind$cos2[1,])
###
sum(cereal_pca_r$var$cor[1:8,1]^2)
mean(cereal_pca_r$ind$coord[,1]^2)
###
sum(cereal_pca_r$ind$contrib[,1])
sum(cereal_pca_r$var$contrib[1,])
###
sum(cereal_pca_r$ind$contrib[,1])
sum(cereal_pca_r$var$contrib[1,])
###
sum(cereal_pca_r$ind$contrib[1:100,1])
###
sum(cereal_pca_r$ind$contrib[,1])
sum(cereal_pca_r$var$contrib[1,])
###
sum(cereal_pca_r$ind$contrib[,1])
###
sum(cereal_pca_r$ind$contrib[1:100,1])
###
sum(cereal_pca_r$ind$contrib[1:10,1])
###
sum(cereal_pca_r$ind$contrib[1:20,1])
###
sum(cereal_pca_r$ind$contrib[1:74,1])
## Import data set from the web
url="http://lib.stat.cmu.edu/datasets/1993.expo/cereal"
cereals <- read.table(url, header=FALSE, as.is=TRUE, na.strings="-1")
# or from local file
cereals <- read.table("cereal.txt", header=TRUE, as.is=TRUE, na.strings="-1")
## Import data set from the web
url="http://lib.stat.cmu.edu/datasets/1993.expo/cereal"
cereals <- read.table(url, header=FALSE, as.is=TRUE, na.strings="-1")
# or from local file
cereals <- read.table("cereal.txt", header=TRUE, as.is=TRUE, na.strings="-1")
# or from local file
cereals <- read.table("/home/philipp/Programming/RProjects/basicDataManipulationAndGraphics/cereal.txt", header=TRUE, as.is=TRUE, na.strings="-1")
names(cereals) <- c('name','mfr','type','calories','protein','fat','sodium','fiber','carbo',
'sugars','shelf','potass','vitamins','weight','cups')
#checking for missing data and its number
sum(is.na(cereals))
#deleting missing values, creating new data frame cereal. There exist imputation methods, but we're not studying them.
cereals=na.omit(cereals)
str(cereals)
# Creating a factor
cereals$shelf <- factor(cereals$shelf, levels=1:3, ordered=TRUE)
cereals$shelf
table(cereals$shelf)
cereals$shelfC <- recode(cereals$shelf, " 1='low'; 2='medium'; 3='high' ")
# Basic statistical summary of the data set
summary(cereals)
## Skewness and kurtosis, need package "moments" to be loaded.
apply(cereals[,7:10],2, kurtosis)
## Skewness and kurtosis, need package "moments" to be loaded.
library(kurtosis)
## Skewness and kurtosis, need package "moments" to be loaded.
library("kurtosis")
library(tm)
library(ggplot2)
library(tm)
install.packages("tm")
library(tm)
library(ggplot2)
library(wordcount2)
install.packages("wordcloud")
library(wordcount2)
library(wordlcloud)
library(wordcloud)
source.pos = DirSource("/home/philipp/Programming/RProjects/NLP/txt_sentoken/pos", encoding="UTF-8")
corpus = Corpus(source.pos)
tdm = TermDocumentMatrix(corpus)
inspect(tdm[2000:2003,100:103])
freq = rowSums(as.matrix((tdm)))
install.packages()
install.packages(shiny)
"shiny"
install.packages("shiny")
library("shiny")
library(shiny)
runExample("01_hello")
library(shiny)
# Define UI for app that draws a histogram ----
ui <- fluidPage(
# App title ----
titlePanel("Hello Shiny!"),
# Sidebar layout with input and output definitions ----
sidebarLayout(
# Sidebar panel for inputs ----
sidebarPanel(
# Input: Slider for the number of bins ----
sliderInput(inputId = "bins",
label = "Number of bins:",
min = 1,
max = 50,
value = 30)
),
# Main panel for displaying outputs ----
mainPanel(
# Output: Histogram ----
plotOutput(outputId = "distPlot")
)
)
)
# Define server logic required to draw a histogram ----
server <- function(input, output) {
# Histogram of the Old Faithful Geyser Data ----
# with requested number of bins
# This expression that generates a histogram is wrapped in a call
# to renderPlot to indicate that:
#
# 1. It is "reactive" and therefore should be automatically
#    re-executed when inputs (input$bins) change
# 2. Its output type is a plot
output$distPlot <- renderPlot({
x    <- faithful$waiting
bins <- seq(min(x), max(x), length.out = input$bins + 1)
hist(x, breaks = bins, col = "#75AADB", border = "white",
xlab = "Waiting time to next eruption (in mins)",
main = "Histogram of waiting times")
})
}
shinyApp(ui = ui, server = server)
runApp("/home/philipp/Programming/dataVisualization/exercise1/App-1/app.R")
runApp("/home/philipp/Programming/dataVisualization/exercise1/App-1/app.R")
runApp("/home/philipp/Programming/dataVisualization/exercise1/App-1/app.R", display.mode = "showcase")
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
library(shiny)
h1("my title")
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
runApp('Programming/dataVisualization/exercise1/lesson2/App-1')
library(tm)
library(wordcloud)
library(SnowballC)
library(RWeka)
pwd
library(tm)
library(wordcloud)
library(SnowballC)
library(RWeka)
library(ggplot2)
library(reshape2)
library(sentimentr)
library(qdap)
library(e1071)
library(gmodels)
library(RTextTools)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
emails <- read.csv('emails.csv')
head(emails$text)
length(emails$text)
table(factor(emails$spam))
table(is.na(emails$spam))
removeEmailAddress <- function(x) {
gsub(pattern = "\\w*[[:blank:]][[:punct:]][[:blank:]]\\w*[[:blank:]][[:punct:]][[:blank:]]com[[:blank:]]", replacement = "", x)
}
removeNumeration <- function(x) {
gsub(pattern = "[[:digit:]][[:blank:]]th", replacement = "", x)
}
pal = brewer.pal(8, "Blues")
pal = pal[-(1:3)]
set.seed(1234)
corpus <- VCorpus(VectorSource(emails$text))
inspect(corpus[[4]])
corpus_lowercase <- tm_map(corpus, content_transformer(tolower))
inspect(corpus_lowercase[[1]])
corpus_noEmailAddress <- tm_map(corpus_lowercase, content_transformer(removeEmailAddress))
inspect(corpus_noEmailAddress[[4]])
corpus_noNumeration <- tm_map(corpus_noEmailAddress, content_transformer(removeNumeration))
corpus.ngrams = tm_map(corpus_noNumeration,removeWords,c(stopwords(),"re", "ect", "hou", "e", "mail", "kaminski", "hou", "cc", "subject", "vince", "j", "enron", "http"))
corpus.ngrams = tm_map(corpus.ngrams,removePunctuation)
# corpus.ngrams = tm_map(corpus.ngrams, removeURLs)
corpus.ngrams = tm_map(corpus.ngrams,removeNumbers)
tdm = TermDocumentMatrix(corpus.ngrams)
tdm
tdm.small <- removeSparseTerms(tdm, sparse = 0.9)
tdm.small
xMatrix <- as.matrix(tdm.small)
y <- emails$spam
data <- as.data.frame(cbind(y,xMatrix))
View(data)
##################### BUILD MODEL TO CLASSIFY E-MAILS AS SPAM OR NOT SPAM #####################
tdm = DocumentTermMatrix(corpus.ngrams)
##################### BUILD MODEL TO CLASSIFY E-MAILS AS SPAM OR NOT SPAM #####################
dtm = DocumentTermMatrix(corpus.ngrams)
dtm
dtm.small <- removeSparseTerms(dtm, sparse = 0.9)
dtm.small
xMatrix <- as.matrix(dtm.small)
y <- emails$spam
data <- as.data.frame(cbind(y,xMatrix))
View(data)
# split into test and train
train.index <- sample(1:length(y), size=floor(.8*length(y)), replace=FALSE)
train <- data[train.index,]
test <- data[-train.index,]
# fit the svm and do a simple validation test. Cost parameter should be tuned.
sv <- svm(y~., train, type="C-classification", kernel="linear", cost=1)
table(Pred=predict(sv, test[,-1]) , True=test$y)
df = as.data.frame(corpus.ngrams)
sentiment = sentiment_by(df$text)
summary(sentiment$ave_sentiment)
qplot(sentiment$ave_sentiment, geom="histogram",binwidth=0.1,main="Review Sentiment Histogram")
View(sentiment)
sentiment <- sentiment$ave_sentiment
sentiment = sentiment_by(df$text)
summary(sentiment$ave_sentiment)
qplot(sentiment$ave_sentiment, geom="histogram",binwidth=0.1,main="Review Sentiment Histogram")
sentiments <- sentiment$ave_sentiment
data <- as.data.frame(cbind(y,xMatrix, sentiments))
View(data)
View(data)
# split into test and train
train.index <- sample(1:length(y), size=floor(.8*length(y)), replace=FALSE)
train <- data[train.index,]
test <- data[-train.index,]
# fit the svm and do a simple validation test. Cost parameter should be tuned.
sv <- svm(y~., train, type="C-classification", kernel="linear", cost=1)
table(Pred=predict(sv, test[,-1]) , True=test$y)
